import gradio as gr
import torch
import torchvision.models as models
import torchvision.transforms as transforms
import cv2
import numpy as np
import time
import os
import urllib.request
from ultralytics import YOLO

# ğŸ“Œ Model indirme linkleri
MODEL_LINKS = {
    "YOLOv5s": "https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5su.pt",
    "YOLOv8n": "https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt",
    "Faster R-CNN": "https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth",
    "SSD": "https://download.pytorch.org/models/ssd300_vgg16_coco-b556d3b4.pth"
}

MODEL_TYPES = {
    "YOLOv5s": "yolo",
    "YOLOv8n": "yolo",
    "Faster R-CNN": "torchvision",
    "SSD": "torchvision"
}

MODEL_PATHS = {name: f"models/{name.replace(' ', '_').lower()}.pt" for name in MODEL_LINKS.keys()}

# ğŸ“Œ Modelleri indir
def download_models():
    os.makedirs("models", exist_ok=True)
    for model_name, url in MODEL_LINKS.items():
        model_path = MODEL_PATHS[model_name]
        if not os.path.exists(model_path) or os.path.getsize(model_path) < 1000:
            print(f"ğŸ“¥ {model_name} indiriliyor...")
            urllib.request.urlretrieve(url, model_path)
            print(f"âœ… {model_name} baÅŸarÄ±yla indirildi!")
        else:
            print(f"ğŸ“ {model_name} zaten mevcut, indirme atlandÄ±.")

# ğŸ“Œ Model indir ve yÃ¼kle
download_models()
models_dict = {}

for name, path in MODEL_PATHS.items():
    try:
        model_type = MODEL_TYPES[name]

        if model_type == "yolo":
            models_dict[name] = YOLO(path)

        elif model_type == "torchvision":
            if name == "Faster R-CNN":
                models_dict[name] = models.detection.fasterrcnn_resnet50_fpn(weights=None)
                models_dict[name].load_state_dict(torch.load(path))
                models_dict[name].eval()

            elif name == "SSD":
                models_dict[name] = models.detection.ssd300_vgg16(weights=None)
                models_dict[name].load_state_dict(torch.load(path))
                models_dict[name].eval()

        print(f"âœ… {name} baÅŸarÄ±yla yÃ¼klendi.")

    except Exception as e:
        print(f"âŒ {name} yÃ¼klenirken hata oluÅŸtu: {e}")

def draw_boxes(image, boxes, labels, scores, thickness=2, color=(0, 255, 0)):
    """Tespit edilen nesneleri gÃ¶rÃ¼ntÃ¼ Ã¼zerine Ã§izer."""
    for box, label, score in zip(boxes, labels, scores):
        x1, y1, x2, y2 = map(int, box)
        cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)
        cv2.putText(image, f"{label}: {score:.2f}", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, thickness)
    return image

def detect_objects(image, selected_models, threshold=0.5, thickness=2, color="#00FF00"):
    """
    SeÃ§ili modeller ile gÃ¶rÃ¼ntÃ¼de nesne tespiti yapar.
    KullanÄ±cÄ± tarafÄ±ndan belirlenen threshold, Ã§izgi kalÄ±nlÄ±ÄŸÄ± ve renk ayarlarÄ±nÄ± uygular.
    """
    output_results = {
        "YOLOv5s": (None, "", ""),
        "YOLOv8n": (None, "", ""),
        "Faster R-CNN": (None, "", ""),
        "SSD": (None, "", "")
    }

    if not selected_models:
        return tuple(output_results.values())  # Hata almamak iÃ§in statik Ã§Ä±ktÄ±

    # ğŸ¨ Renk kodunun doÄŸru formatta olduÄŸunu kontrol et
    if not isinstance(color, str) or not color.startswith("#"):
        color = "#00FF00"  # VarsayÄ±lan yeÅŸil

    try:
        # ğŸ“Œ HEX -> RGB Ã§evir
        color = color.lstrip("#")
        color = (int(color[0:2], 16), int(color[2:4], 16), int(color[4:6], 16))  # RGB formatÄ±
        color = color[::-1]  # OpenCV iÃ§in BGR formatÄ±
    except Exception as e:
        print(f"ğŸš¨ Renk dÃ¶nÃ¼ÅŸtÃ¼rme hatasÄ±: {e}")
        color = (0, 255, 0)  # VarsayÄ±lan yeÅŸil BGR

    for model_name in output_results.keys():
        if model_name in selected_models:
            model = models_dict.get(model_name, None)
            if not model:
                print(f"ğŸš¨ {model_name} modeli YÃœKLENEMEDÄ°!")
                continue

            model_type = MODEL_TYPES[model_name]

            # ğŸ“Œ Model inference baÅŸlat
            start_time = time.time()

            try:
                if model_type == "yolo":
                    results = model(image)
                    results = [r for r in results if r.boxes.conf.max() >= threshold]  # Threshold filtresi
                    output_image = results[0].plot(line_width=thickness)
                    detected_objects = [(model.names[int(box.cls[0])], round(float(box.conf[0]), 2)) for result in results for box in result.boxes]

                elif model_type == "torchvision":
                    transform = transforms.Compose([transforms.ToTensor()])
                    image_tensor = transform(image).unsqueeze(0)
                    predictions = model(image_tensor)[0]

                    boxes = predictions["boxes"].detach().cpu().numpy()
                    labels = predictions["labels"].detach().cpu().numpy()
                    scores = predictions["scores"].detach().cpu().numpy()

                    filtered_indices = scores >= threshold  # Threshold filtresi
                    boxes, labels, scores = boxes[filtered_indices], labels[filtered_indices], scores[filtered_indices]

                    detected_objects = [(int(label), round(float(score), 2)) for label, score in zip(labels, scores)]
                    output_image = np.array(image)
                    output_image = draw_boxes(output_image, boxes, labels, scores, thickness, color)

                end_time = time.time()
                inference_time = round(end_time - start_time, 3)

                print(f"âœ… {model_name} Ã‡ALIÅTI! - {inference_time} saniye")

                output_results[model_name] = (output_image, str(detected_objects), f"{model_name} tamamlandÄ± - {inference_time} saniye")

            except Exception as e:
                print(f"ğŸš¨ HATA! {model_name} Ã§alÄ±ÅŸÄ±rken hata oluÅŸtu: {e}")

     # ğŸ“Œ TÃ¼m modellerin Ã§Ä±ktÄ±sÄ±nÄ± dÃ¶ndÃ¼rerek Gradio'nun hata vermesini Ã¶nle
    return (
        output_results["YOLOv5s"][0], output_results["YOLOv5s"][1], output_results["YOLOv5s"][2],
        output_results["YOLOv8n"][0], output_results["YOLOv8n"][1], output_results["YOLOv8n"][2],
        output_results["Faster R-CNN"][0], output_results["Faster R-CNN"][1], output_results["Faster R-CNN"][2],
        output_results["SSD"][0], output_results["SSD"][1], output_results["SSD"][2]
    )


def select_all():
    """TÃ¼m modelleri seÃ§mek iÃ§in kullanÄ±lan fonksiyon"""
    return list(MODEL_PATHS.keys())

# ğŸ“Œ Gradio ArayÃ¼zÃ¼
with gr.Blocks() as demo:
    gr.Markdown("# MLModelHub - Ã–nceden EÄŸitilmiÅŸ Modellerle Nesne Tespiti")

    with gr.Row():
        image_input = gr.Image(type="numpy", label="ğŸ–¼ Resim YÃ¼kle")

    with gr.Row():
        model_selection = gr.CheckboxGroup(choices=list(MODEL_PATHS.keys()), label="ğŸ“Œ Modelleri SeÃ§")

    with gr.Accordion("âš™ï¸ **GeliÅŸmiÅŸ Ayarlar**", open=False):
        threshold_slider = gr.Slider(0.1, 1.0, value=0.5, step=0.05, label="ğŸ¯ Threshold")
        thickness_slider = gr.Slider(1, 10, value=2, step=1, label="ğŸ– Ã‡izgi KalÄ±nlÄ±ÄŸÄ±")
        color_picker = gr.ColorPicker(value="#00FF00", label="ğŸ¨ Kutu Rengi")

    detect_button = gr.Button("ğŸš€ Nesneleri Bul")

    # ğŸ“Œ Her model iÃ§in sabit Ã§Ä±ktÄ± alanlarÄ±
    yolo_v5_image = gr.Image(label="YOLOv5s - SonuÃ§")
    yolo_v5_objects = gr.Textbox(label="YOLOv5s - Tespit Edilen Nesneler")
    yolo_v5_time = gr.Textbox(label="YOLOv5s - Inference SÃ¼resi")

    yolo_v8_image = gr.Image(label="YOLOv8n - SonuÃ§")
    yolo_v8_objects = gr.Textbox(label="YOLOv8n - Tespit Edilen Nesneler")
    yolo_v8_time = gr.Textbox(label="YOLOv8n - Inference SÃ¼resi")

    faster_rcnn_image = gr.Image(label="Faster R-CNN - SonuÃ§")
    faster_rcnn_objects = gr.Textbox(label="Faster R-CNN - Tespit Edilen Nesneler")
    faster_rcnn_time = gr.Textbox(label="Faster R-CNN - Inference SÃ¼resi")

    ssd_image = gr.Image(label="SSD - SonuÃ§")
    ssd_objects = gr.Textbox(label="SSD - Tespit Edilen Nesneler")
    ssd_time = gr.Textbox(label="SSD - Inference SÃ¼resi")

    detect_button.click(
        detect_objects, 
        inputs=[image_input, model_selection, threshold_slider, thickness_slider, color_picker], 
        outputs=[
            yolo_v5_image, yolo_v5_objects, yolo_v5_time,
            yolo_v8_image, yolo_v8_objects, yolo_v8_time,
            faster_rcnn_image, faster_rcnn_objects, faster_rcnn_time,
            ssd_image, ssd_objects, ssd_time
        ]
    )

demo.launch()
