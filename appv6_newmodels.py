import gradio as gr
import torch
import torchvision.models as models
import torchvision.transforms as transforms
import cv2
import numpy as np
import time
import os
import urllib.request
from ultralytics import YOLO
import matplotlib.pyplot as plt
import io
import base64

os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

# ğŸ“Œ Model indirme linkleri
MODEL_LINKS = {
    # YOLO Serisi
    #  YOLOv5n: https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5n-cls.pt
    "YOLOv5s": "https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s-cls.pt",
    "YOLOv5m": "https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5m-cls.pt",
    "YOLOv5l": "https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5l-cls.pt",
    "YOLOv5x": "https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5x-cls.pt",

    "YOLOv7": "https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt",
    "YOLOv8n": "https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt",
    "YOLOv8m": "https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt",
    "YOLOv8l": "https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l.pt",
    "YOLOv8x": "https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x.pt",

    # Torchvision Detection Modelleri
    "Faster R-CNN": "https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth",
    "SSD": "https://download.pytorch.org/models/ssd300_vgg16_coco-b556d3b4.pth",
    "RetinaNet": "https://download.pytorch.org/models/retinanet_resnet50_fpn_coco-eeacb38b.pth",
    "Mask R-CNN": "https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth",
    "Keypoint R-CNN": "https://download.pytorch.org/models/keypointrcnn_resnet50_fpn_coco-fc266e95.pth",
    "DETR": "https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth",

    # Segmentasyon Modelleri
    #"DeepLabV3": "https://download.pytorch.org/models/deeplabv3_resnet50_coco-586e9d54.pth"
}

# ğŸ“Œ Model tÃ¼rlerini belirleme
MODEL_TYPES = {name: "yolo" if "YOLO" in name else "torchvision" for name in MODEL_LINKS.keys()}

# ğŸ“Œ Model yollarÄ±
MODEL_PATHS = {name: f"models/{name.replace(' ', '_').lower()}.pt" for name in MODEL_LINKS.keys()}

# ğŸ“Œ Modelleri indir
def download_models():
    os.makedirs("models", exist_ok=True)
    for model_name, url in MODEL_LINKS.items():
        model_path = MODEL_PATHS[model_name]
        if not os.path.exists(model_path) or os.path.getsize(model_path) < 1000:
            print(f"ğŸ“¥ {model_name} indiriliyor...")
            urllib.request.urlretrieve(url, model_path)
            print(f"âœ… {model_name} baÅŸarÄ±yla indirildi!")
        else:
            print(f"ğŸ“ {model_name} zaten mevcut, indirme atlandÄ±.")

# ğŸ“Œ Modelleri indir ve yÃ¼kle
download_models()
models_dict = {}

for name, path in MODEL_PATHS.items():
    try:
        if MODEL_TYPES[name] == "yolo":
            models_dict[name] = YOLO(path)
        else:
            if name == "Faster R-CNN":
                models_dict[name] = models.detection.fasterrcnn_resnet50_fpn(weights=None)
            elif name == "SSD":
                models_dict[name] = models.detection.ssd300_vgg16(weights=None)
            elif name == "RetinaNet":
                models_dict[name] = models.detection.retinanet_resnet50_fpn(weights=None)
            elif name == "Mask R-CNN":
                models_dict[name] = models.detection.maskrcnn_resnet50_fpn(weights=None)
            elif name == "Keypoint R-CNN":
                models_dict[name] = models.detection.keypointrcnn_resnet50_fpn(weights=None)
            elif name == "DETR":
                models_dict[name] = models.detection.detr_resnet50(weights=None)
            #elif name == "DeepLabV3":
            #    models_dict[name] = models.segmentation.deeplabv3_resnet50(weights=None)

            models_dict[name].load_state_dict(torch.load(path))
            models_dict[name].eval()
        
        print(f"âœ… {name} baÅŸarÄ±yla yÃ¼klendi.")

    except Exception as e:
        print(f"âŒ {name} yÃ¼klenirken hata oluÅŸtu: {e}")

def detect_objects(image, selected_models, threshold=0.5, thickness=2, color="#00FF00"):
    """
    SeÃ§ili modeller ile gÃ¶rÃ¼ntÃ¼de nesne tespiti yapar.
    KullanÄ±cÄ± tarafÄ±ndan belirlenen threshold, Ã§izgi kalÄ±nlÄ±ÄŸÄ± ve renk ayarlarÄ±nÄ± uygular.
    """
    
    # ğŸ“Œ VarsayÄ±lan Ã§Ä±ktÄ± yapÄ±sÄ± (TÃ¼m modeller iÃ§in)
    output_results = {model_name: (None, "", "") for model_name in MODEL_PATHS.keys()}
    
    inference_times = {}  # Inference sÃ¼relerini saklar
    detection_counts = {}  # Tespit edilen nesne sayÄ±sÄ±nÄ± saklar

    if not selected_models:
        return tuple(output_results.values())  # Hata almamak iÃ§in statik Ã§Ä±ktÄ±

    # ğŸ¨ Renk kodunun doÄŸru formatta olduÄŸunu kontrol et
    try:
        color = color.lstrip("#")
        color = (int(color[0:2], 16), int(color[2:4], 16), int(color[4:6], 16))  # RGB formatÄ±
        color = color[::-1]  # OpenCV iÃ§in BGR formatÄ±
    except Exception as e:
        print(f"ğŸš¨ Renk dÃ¶nÃ¼ÅŸtÃ¼rme hatasÄ±: {e}")
        color = (0, 255, 0)  # VarsayÄ±lan yeÅŸil BGR

    for model_name in selected_models:
        model = models_dict.get(model_name, None)
        if not model:
            print(f"ğŸš¨ {model_name} modeli YÃœKLENEMEDÄ°!")
            continue

        model_type = MODEL_TYPES[model_name]

        # ğŸ“Œ Model inference baÅŸlat
        start_time = time.time()

        try:
            if model_type == "yolo":
                results = model(image)
                results = [r for r in results if r.boxes.conf.max() >= threshold]  # Threshold filtresi
                output_image = results[0].plot(line_width=thickness)
                detected_objects = [(model.names[int(box.cls[0])], round(float(box.conf[0]), 2)) for result in results for box in result.boxes]

            elif model_type == "torchvision":
                transform = transforms.Compose([transforms.ToTensor()])
                image_tensor = transform(image).unsqueeze(0)
                predictions = model(image_tensor)[0]

                # EÄŸer model bounding box iÃ§eriyorsa (Detections)
                if "boxes" in predictions:
                    boxes = predictions["boxes"].detach().cpu().numpy()
                    labels = predictions["labels"].detach().cpu().numpy()
                    scores = predictions["scores"].detach().cpu().numpy()
                    
                    filtered_indices = scores >= threshold  # Threshold filtresi
                    boxes, labels, scores = boxes[filtered_indices], labels[filtered_indices], scores[filtered_indices]

                    detected_objects = [(int(label), round(float(score), 2)) for label, score in zip(labels, scores)]
                    output_image = np.array(image)
                    output_image = draw_boxes(output_image, boxes, labels, scores, thickness, color)

                # EÄŸer model segmentasyon yapÄ±yorsa (Ã¶rneÄŸin Mask R-CNN, DeepLabV3)
                elif "masks" in predictions:
                    masks = predictions["masks"].detach().cpu().numpy()
                    masks = masks > 0.5  # Maske eÅŸik deÄŸeri uygula

                    output_image = np.array(image)
                    for mask in masks:
                        mask = (mask * 255).astype(np.uint8)
                        contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
                        cv2.drawContours(output_image, contours, -1, color, thickness)

                    detected_objects = [("Segmentation", len(masks))]

                else:
                    detected_objects = [("No objects detected", 0)]
                    output_image = np.array(image)

            end_time = time.time()
            inference_time = round(end_time - start_time, 3)

            print(f"âœ… {model_name} Ã‡ALIÅTI! - {inference_time} saniye")
            inference_times[model_name] = inference_time  # Inference sÃ¼resini kaydet
            detection_counts[model_name] = len(detected_objects)  # Tespit edilen nesne sayÄ±sÄ±nÄ± kaydet
            output_results[model_name] = (output_image, str(detected_objects), f"{model_name} tamamlandÄ± - {inference_time} saniye")

        except Exception as e:
            print(f"ğŸš¨ HATA! {model_name} Ã§alÄ±ÅŸÄ±rken hata oluÅŸtu: {e}")

    # ğŸ“Œ Grafik Ã‡Ä±ktÄ±sÄ± (Performans Analizi)
    graph_figure = plot_results(inference_times, detection_counts)
    
    return (
        *[output_results[model][0:3] for model in MODEL_PATHS.keys()],
        graph_figure  # Base64 yerine Matplotlib figÃ¼rÃ¼nÃ¼ dÃ¶ndÃ¼r
    )

def draw_boxes(image, boxes, labels, scores, thickness=2, color=(0, 255, 0)):
    """Tespit edilen nesneleri gÃ¶rÃ¼ntÃ¼ Ã¼zerine Ã§izer."""
    for box, label, score in zip(boxes, labels, scores):
        x1, y1, x2, y2 = map(int, box)
        cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)
        cv2.putText(image, f"{label}: {score:.2f}", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, thickness)
    return image

def plot_results(inference_times, detection_counts):
    """
    Inference sÃ¼resi ve tespit edilen nesne sayÄ±sÄ±nÄ± karÅŸÄ±laÅŸtÄ±ran bir grafik oluÅŸturur.
    """
    models = list(inference_times.keys())
    times = list(inference_times.values())
    detections = list(detection_counts.values())

    fig, ax1 = plt.subplots(figsize=(8, 5))

    # Ã‡ubuk grafiÄŸi (Inference SÃ¼resi)
    ax1.bar(models, times, color='b', alpha=0.6, label="Inference SÃ¼resi (saniye)")

    # Ä°kinci y ekseni (Tespit Edilen Nesne SayÄ±sÄ±)
    ax2 = ax1.twinx()
    ax2.plot(models, detections, color='r', marker='o', markersize=8, linewidth=2, label="Tespit Edilen Nesne SayÄ±sÄ±")

    # Eksen etiketleri
    ax1.set_xlabel("Modeller")
    ax1.set_ylabel("Inference SÃ¼resi (saniye)", color='b')
    ax2.set_ylabel("Tespit Edilen Nesne SayÄ±sÄ±", color='r')

    # BaÅŸlÄ±k ve Grid
    ax1.set_title("Modellerin Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±")
    ax1.grid(axis='y', linestyle='--', alpha=0.7)

    # Legend
    ax1.legend(loc="upper left")
    ax2.legend(loc="upper right")

    return fig  # Base64 yerine doÄŸrudan fig nesnesini dÃ¶ndÃ¼r


# ğŸ“Œ Gradio ArayÃ¼zÃ¼
with gr.Blocks() as demo:
    gr.Markdown("# MLModelHub - Ã–nceden EÄŸitilmiÅŸ Modellerle Nesne Tespiti")

    with gr.Row():
        image_input = gr.Image(type="numpy", label="ğŸ–¼ Resim YÃ¼kle")

    with gr.Row():
        model_selection = gr.CheckboxGroup(choices=list(MODEL_PATHS.keys()), label="ğŸ“Œ Modelleri SeÃ§")

    with gr.Accordion("âš™ï¸ **GeliÅŸmiÅŸ Ayarlar**", open=False):
        threshold_slider = gr.Slider(0.1, 1.0, value=0.5, step=0.05, label="ğŸ¯ Threshold")
        thickness_slider = gr.Slider(1, 10, value=2, step=1, label="ğŸ– Ã‡izgi KalÄ±nlÄ±ÄŸÄ±")
        color_picker = gr.ColorPicker(value="#00FF00", label="ğŸ¨ Kutu Rengi")

    detect_button = gr.Button("ğŸš€ Nesneleri Bul")

    # ğŸ“Œ Her model iÃ§in sabit Ã§Ä±ktÄ± alanlarÄ±
    yolo_v5s_image = gr.Image(label="YOLOv5s - SonuÃ§")
    yolo_v5s_objects = gr.Textbox(label="YOLOv5s - Tespit Edilen Nesneler")
    yolo_v5s_time = gr.Textbox(label="YOLOv5s - Inference SÃ¼resi")

    yolo_v5m_image = gr.Image(label="YOLOv5m - SonuÃ§")
    yolo_v5m_objects = gr.Textbox(label="YOLOv5m - Tespit Edilen Nesneler")
    yolo_v5m_time = gr.Textbox(label="YOLOv5m - Inference SÃ¼resi")

    yolo_v5l_image = gr.Image(label="YOLOv5l - SonuÃ§")
    yolo_v5l_objects = gr.Textbox(label="YOLOv5l - Tespit Edilen Nesneler")
    yolo_v5l_time = gr.Textbox(label="YOLOv5l - Inference SÃ¼resi")

    yolo_v5x_image = gr.Image(label="YOLOv5x - SonuÃ§")
    yolo_v5x_objects = gr.Textbox(label="YOLOv5x - Tespit Edilen Nesneler")
    yolo_v5x_time = gr.Textbox(label="YOLOv5x - Inference SÃ¼resi")

    yolo_v7_image = gr.Image(label="YOLOv7 - SonuÃ§")
    yolo_v7_objects = gr.Textbox(label="YOLOv7 - Tespit Edilen Nesneler")
    yolo_v7_time = gr.Textbox(label="YOLOv7 - Inference SÃ¼resi")

    yolo_v8n_image = gr.Image(label="YOLOv8n - SonuÃ§")
    yolo_v8n_objects = gr.Textbox(label="YOLOv8n - Tespit Edilen Nesneler")
    yolo_v8n_time = gr.Textbox(label="YOLOv8n - Inference SÃ¼resi")

    yolo_v8m_image = gr.Image(label="YOLOv8m - SonuÃ§")
    yolo_v8m_objects = gr.Textbox(label="YOLOv8m - Tespit Edilen Nesneler")
    yolo_v8m_time = gr.Textbox(label="YOLOv8m - Inference SÃ¼resi")

    yolo_v8l_image = gr.Image(label="YOLOv8l - SonuÃ§")
    yolo_v8l_objects = gr.Textbox(label="YOLOv8l - Tespit Edilen Nesneler")
    yolo_v8l_time = gr.Textbox(label="YOLOv8l - Inference SÃ¼resi")

    yolo_v8x_image = gr.Image(label="YOLOv8x - SonuÃ§")
    yolo_v8x_objects = gr.Textbox(label="YOLOv8x - Tespit Edilen Nesneler")
    yolo_v8x_time = gr.Textbox(label="YOLOv8x - Inference SÃ¼resi")

    faster_rcnn_image = gr.Image(label="Faster R-CNN - SonuÃ§")
    faster_rcnn_objects = gr.Textbox(label="Faster R-CNN - Tespit Edilen Nesneler")
    faster_rcnn_time = gr.Textbox(label="Faster R-CNN - Inference SÃ¼resi")

    ssd_image = gr.Image(label="SSD - SonuÃ§")
    ssd_objects = gr.Textbox(label="SSD - Tespit Edilen Nesneler")
    ssd_time = gr.Textbox(label="SSD - Inference SÃ¼resi")

    retinanet_image = gr.Image(label="RetinaNet - SonuÃ§")
    retinanet_objects = gr.Textbox(label="RetinaNet - Tespit Edilen Nesneler")
    retinanet_time = gr.Textbox(label="RetinaNet - Inference SÃ¼resi")

    mask_rcnn_image = gr.Image(label="Mask R-CNN - SonuÃ§")
    mask_rcnn_objects = gr.Textbox(label="Mask R-CNN - Tespit Edilen Nesneler")
    mask_rcnn_time = gr.Textbox(label="Mask R-CNN - Inference SÃ¼resi")

    keypoint_rcnn_image = gr.Image(label="Keypoint R-CNN - SonuÃ§")
    keypoint_rcnn_objects = gr.Textbox(label="Keypoint R-CNN - Tespit Edilen Nesneler")
    keypoint_rcnn_time = gr.Textbox(label="Keypoint R-CNN - Inference SÃ¼resi")

    detr_image = gr.Image(label="DETR - SonuÃ§")
    detr_objects = gr.Textbox(label="DETR - Tespit Edilen Nesneler")
    detr_time = gr.Textbox(label="DETR - Inference SÃ¼resi")

    deeplabv3_image = gr.Image(label="DeepLabV3 - SonuÃ§")
    deeplabv3_objects = gr.Textbox(label="DeepLabV3 - Tespit Edilen Nesneler")
    deeplabv3_time = gr.Textbox(label="DeepLabV3 - Inference SÃ¼resi")

    performance_graph = gr.Plot(label="ğŸ“Š Model Performans GrafiÄŸi")  # Performans grafiÄŸi alanÄ±

    detect_button.click(
        detect_objects, 
        inputs=[image_input, model_selection, threshold_slider, thickness_slider, color_picker], 
        outputs=[
            yolo_v5s_image, yolo_v5s_objects, yolo_v5s_time,
            yolo_v5m_image, yolo_v5m_objects, yolo_v5m_time,
            yolo_v5l_image, yolo_v5l_objects, yolo_v5l_time,
            yolo_v5x_image, yolo_v5x_objects, yolo_v5x_time,
            yolo_v7_image, yolo_v7_objects, yolo_v7_time,
            yolo_v8n_image, yolo_v8n_objects, yolo_v8n_time,
            yolo_v8m_image, yolo_v8m_objects, yolo_v8m_time,
            yolo_v8l_image, yolo_v8l_objects, yolo_v8l_time,
            yolo_v8x_image, yolo_v8x_objects, yolo_v8x_time,
            faster_rcnn_image, faster_rcnn_objects, faster_rcnn_time,
            ssd_image, ssd_objects, ssd_time,
            retinanet_image, retinanet_objects, retinanet_time,
            mask_rcnn_image, mask_rcnn_objects, mask_rcnn_time,
            keypoint_rcnn_image, keypoint_rcnn_objects, keypoint_rcnn_time,
            detr_image, detr_objects, detr_time,
            deeplabv3_image, deeplabv3_objects, deeplabv3_time,
            performance_graph  # ğŸ“Š Performans grafiÄŸi burada ekleniyor
        ]
    )

demo.launch()



# ğŸ“Œ Yeni Sayfa (Multi-page Route)
with demo.route("YOLOv5s", "/yolo-v5s"):
        gr.Markdown("# ğŸš€ YOLOv5s - Derinlemesine Ä°nceleme")
        
        gr.Markdown("### **ğŸ“Œ YOLOv5s Nedir?**")
        gr.Markdown(
            "YOLOv5s (You Only Look Once v5 - Small), **Ultralytics** tarafÄ±ndan geliÅŸtirilen "
            "**YOLO nesne tespiti** ailesine ait bir modeldir. 's' versiyonu, **hafif, hÄ±zlÄ± ve dÃ¼ÅŸÃ¼k gecikmeli** "
            "olmasÄ±yla bilinir. KÃ¼Ã§Ã¼k boyutu sayesinde **mobil cihazlar ve gÃ¶mÃ¼lÃ¼ sistemlerde kolayca Ã§alÄ±ÅŸabilir**. "
            "**COCO dataset** Ã¼zerinde eÄŸitilmiÅŸ olup 80 farklÄ± nesneyi tanÄ±yabilir."
        )

        gr.Markdown("### **ğŸ›  YOLOv5s'nin Mimari YapÄ±sÄ±**")
        gr.Markdown(
            "**YOLOv5s modeli Ã¼Ã§ ana bileÅŸenden oluÅŸur:**\n\n"
            "**1ï¸âƒ£ Backbone (Ã–znitelik Ã‡Ä±karÄ±mÄ±):** CSPDarknet53 kullanÄ±r, residual bloklarla optimize edilmiÅŸtir.\n\n"
            "**2ï¸âƒ£ Neck (Ã–zellik BirleÅŸtirme):** PAFPN (Path Aggregation Feature Pyramid Network) ile FPN+PAN yapÄ±sÄ± kullanÄ±r.\n\n"
            "**3ï¸âƒ£ Head (Tahmin AÅŸamasÄ±):** Nesne kutularÄ±nÄ± tahmin eder, GIoU Loss ile optimize edilmiÅŸtir.\n"
        )

        gr.Markdown("#### **1ï¸âƒ£ Backbone - Feature Extractor**")
        gr.Textbox(
            "Backbone, modelin ham gÃ¶rÃ¼ntÃ¼den Ã¶zellikler Ã§Ä±kardÄ±ÄŸÄ± kÄ±sÄ±mdÄ±r. "
            "CSPDarknet53 kullanÄ±larak residual baÄŸlantÄ±lar eklenmiÅŸ ve hesaplama verimliliÄŸi artÄ±rÄ±lmÄ±ÅŸtÄ±r. "
            "Bu bÃ¶lÃ¼m, Ã§eÅŸitli konvolÃ¼syon katmanlarÄ± ve aktivasyon fonksiyonlarÄ± iÃ§erir.",
            label="ğŸ“Œ Backbone AÃ§Ä±klamasÄ±"
        )

        gr.Markdown("#### **2ï¸âƒ£ Neck - Ã–zellik BirleÅŸtirme**")
        gr.Textbox(
            "Neck katmanÄ±, farklÄ± Ã¶lÃ§eklerdeki nesneleri tespit edebilmek iÃ§in geliÅŸtirilmiÅŸtir. "
            "PAFPN (Path Aggregation Feature Pyramid Network) ile FPN ve PAN bileÅŸenlerini kullanarak "
            "kÃ¼Ã§Ã¼k ve bÃ¼yÃ¼k nesnelerin daha iyi algÄ±lanmasÄ±nÄ± saÄŸlar.",
            label="ğŸ“Œ Neck AÃ§Ä±klamasÄ±"
        )

        gr.Markdown("#### **3ï¸âƒ£ Head - Tahmin AÅŸamasÄ±**")
        gr.Textbox(
            "Head bÃ¶lÃ¼mÃ¼, nesne tespiti iÃ§in nihai tahminleri Ã¼retir. Modelin bounding box koordinatlarÄ±nÄ±, "
            "nesne puanlarÄ±nÄ± ve sÄ±nÄ±f tahminlerini iÃ§erir. Sigmoid aktivasyon fonksiyonu ile olasÄ±lÄ±klar hesaplanÄ±r.",
            label="ğŸ“Œ Head AÃ§Ä±klamasÄ±"
        )

        gr.Markdown("### **ğŸ“Œ Ã–nceden EÄŸitilmiÅŸ Model (Pretrained) Ä°Ã§erisindeki SÄ±nÄ±flar**")
        gr.Textbox(
            "YOLOv5s, COCO veri seti Ã¼zerinde eÄŸitilmiÅŸtir ve 80 farklÄ± sÄ±nÄ±fÄ± tespit edebilir:\n"
            "Person, Bicycle, Car, Motorcycle, Airplane, Bus, Train, Truck, Boat, Traffic light...\n"
            "(TÃ¼m sÄ±nÄ±f listesi iÃ§eriÄŸe eklenmiÅŸtir)",
            label="ğŸ“Œ SÄ±nÄ±f Listesi"
        )

        gr.Markdown("### **ğŸ“Œ YOLOv5s KullanÄ±m AlanlarÄ±**")
        gr.Textbox(
            "ğŸ“· **GÃ¼venlik KameralarÄ±**: GerÃ§ek zamanlÄ± izleme iÃ§in kullanÄ±lÄ±r.\n"
            "ğŸš— **Otonom AraÃ§lar**: Yol Ã¼zerindeki nesneleri tanÄ±r.\n"
            "ğŸ­ **EndÃ¼striyel Ãœretim**: ÃœrÃ¼n kusurlarÄ±nÄ± tespit eder.\n"
            "ğŸ§‘â€âš•ï¸ **TÄ±bbi GÃ¶rÃ¼ntÃ¼leme**: Radyolojik analizlerde kullanÄ±labilir.\n"
            "ğŸŒ¿ **TarÄ±m**: Bitki hastalÄ±klarÄ±nÄ± ve bÃ¶cekleri belirleyebilir.\n"
            "ğŸ›’ **Perakende**: Raf dÃ¼zeni ve envanter yÃ¶netimi iÃ§in kullanÄ±lÄ±r.",
            label="ğŸ“Œ KullanÄ±m AlanlarÄ±"
        )

with demo.route("YOLOv8n", "/yolo-v8n"):
    gr.Markdown("# ğŸ“‚ Yeni Sayfa - Ekstra Bilgiler")
    gr.Markdown("Burada ek bilgileri gÃ¶sterebilirsiniz!")
    gr.Textbox("Bu, yeni sayfada gÃ¶sterilecek bir iÃ§eriktir.", label="ğŸ“Œ AÃ§Ä±klama")

with demo.route("Faster R-CNN", "/faster-r-cnn"):
    gr.Markdown("# ğŸ“‚ Yeni Sayfa - Ekstra Bilgiler")
    gr.Markdown("Burada ek bilgileri gÃ¶sterebilirsiniz!")
    gr.Textbox("Bu, yeni sayfada gÃ¶sterilecek bir iÃ§eriktir.", label="ğŸ“Œ AÃ§Ä±klama")

with demo.route("SSD", "/ssd"):
    gr.Markdown("# ğŸ“‚ Yeni Sayfa - Ekstra Bilgiler")
    gr.Markdown("Burada ek bilgileri gÃ¶sterebilirsiniz!")
    gr.Textbox("Bu, yeni sayfada gÃ¶sterilecek bir iÃ§eriktir.", label="ğŸ“Œ AÃ§Ä±klama")


demo.launch()
